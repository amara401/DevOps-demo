Ref Links:
	-> https://www.youtube.com/watch?v=qaAllMDf_rs
# Volume and vault storage
# What is cloud storage
# Type of AWS storage
# storage option in AWS
	->  EBS*
	-> Simple Storage Service (S3)*
	-> Amazon Glacier -  for long term storage and very very cheap (low cost)
# AWS Connection Storage
	-> Snowball - long term enterprise (Hybride infrastructure)
	-> Storage Gateway - long term enterprise (Hybride infrastructure
Volume: it is harddick volume. ex: folder and files
Vault: Storage device used for archivel data for longer period of time.
Tradetional Storage Tier's:
	-> tier0  ---> Ex: SSD, mostly used for DB's data storage
	-> tier1  ---> Ex: 10k rpm HDD (replication, RAID, mirror)
	-> tier2  ---> Ex: 7.2 rpm NL HDD (Erasure coding, RAID)
	-> tier3  ---> Ex: Cold or tape HDD
-> Performance and cost increase from Tier3 to tier0 ie: tier3 -> tier2 -> tier1 -> tier0
-> Capacity is more in tier3 ie: tier0 -> tier1 -> tier2 -> tier3
-> Tier3 and tier2 used for vault storage and tier0 and tier1 used for Volume
-> 
# Disadvantages of treditinal storage and solution by Cloud:
1) Storage sitting idle in data center - pay infrastructure as u need it and no upfront payment.
2) Inactive data sitting in costly storage - data reduction technique and archiving to store inactive cold data
EBS - it is the block storage - Accessed by one machine at a time - Like a Dard disk but not actually
S3 and Glacier is the Object storage - Accessed directly by mutiple machines -  stored i web API's
Ex: EBS is used for databases (MySql) and application may have show images,videos are stored in S3. Application write/retrive from S3 using web API's. But ur Dbs write/retrive from EBS using OS level machanisim.
-> EBS is in tier0/1 and s3 in tier2 and Glacier in tier3
Storage Gateway - way to intergrate two sides.
Snowball -  mainly for transfer. Ex: Data migration - Transfer the on-premesis data into cloud - Faster data rate and encrypted data while data transfer.
Memory - 
	-> TiB (Tebibyte): 1-TiB = 1.10TB = 1024GiB
	-> GiB (Gibibytes): 1-GiB = 1.07GB = 1024 MiB
	-> MiB (Mebibytes): 1-MiB = 1.05MB = 1024 KIB
	-> KiB (Kibibytes)

###---Elastic Block Storage (EBS)---###
	-> Provide block level storage volumes for EC2 instances. Ex: application , DB's 
	-> EC2 instance must have one r more EBS volumes.
	-> Communcation happen through network b/n EC2 and EC2 not directly attached physically.
	-> You can attach an available EBS volume to one of your instances that is in the same Availability Zone as the volume.
	-> You can detach an Amazon EBS volume from an instance explicitly or by terminating the instance. 
	-> However, if the instance is running, you must first unmount the volume from the instance.
	-> If an EBS volume is the root device of an instance, you must stop the instance before you can detach the volume.	
Ref Links:
	-> Amazon EBS Volumes:
		https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/EBSVolumes.html
	-> Amazon Elastic Block Store (Amazon EBS):
		https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/AmazonEBS.html?shortFooter=true
# EBS Snapshot:
	-> Snapshot is the backup of ur EBS volume and it stored in S3.
	-> It is a incremental backup.
	-> it is encrypted volumes.
Q) Is it possible to change the EBS volume to different availability zones?
Scenario: I have a server created in "eu-west-1c" availability zone and I tried to attach the volume created in "eu-west-1a" availability zone to "eu-west-1c" but the server created in "eu-west-1c" is not reachable. Is it any way to attach among different availability zones?
Ans: When you create an EBS volume in an Availability Zone, it is automatically replicated within that zone to prevent data loss due to failure of any single hardware component. 
     After you create a volume, you can attach it to any EC2 instance in the same Availability Zone.
	 Amazon EBS provides the ability to create snapshots (backups) of any EBS volume and write a copy of the data in the volume to Amazon S3, 
	 where it is stored redundantly in multiple Availability Zones. The volume does not need be attached to a running instance in order to take a snapshot. 
	 As you continue to write data to a volume, you can periodically create a snapshot of the volume to use as a baseline for new volumes. 
	 These snapshots can be used to create multiple new EBS volumes or move volumes across Availability Zones.
Ref: https://serverfault.com/questions/869710/is-it-possible-to-change-the-ebs-volume-to-different-availability-zones/873400
Features of EBS Volumes:
	-> Can be attached to any running instance to same AZ.	 
		   EC2
   _________|_____________
   | 				 	  |
   |				 	  |
   EBS root Volume		EBS Data Volume
   |						|
   Primary Volume		Secondry Volume 
   -> EBS volume can be attached to server or detached from server within the same AZ.
   -> Even after terminate the EC2 instance u can attached EBS volume to an instance. ie. EBS volume (data) still in live.
   -> Encryting the EBS volumes
Types of EBS VOlumes: 
	1) Provision IOPS (SSD) - Large DB's
	2) General Purpose (SSD) - Development and testing Env
	3) Magnetic -  Cold storage
Q) For cold storage which EBS volume will be use? - Ans (C)
	a) Provision IOPS  b) General Purpose	c) Magnetic	 d) None of the above
Q) Does EBS tolerate an AZ failure? - Ans (A)
	a) No, EBS volumes are stored in single AZ	 b) Yes, an EBS volume has multiple cpoies so it should be fine
	c) Depends on how it is setup				 d) Depends on the region where EBS volume is initiated
-> If hole AZ fails  there is no way to revert the EBS volume.
-> We can't attached EBS volumes from one AZ to another AZ. Only possible with in a AZ.
-> Snapshot - A backup of ur EBS volume at that time and by using snapshot recreate your EBS volume.

###---Simple Storage Service (S3)---###
-> It is a Object storage machanisim.
-> Each Amazon S3 object has data (ex: Imageas), a key (it is unique name) and metadata.
-> Uniquely identified within a bucket by a key(name) and a version ID
-> Each object can contain upto 5Tb of data.
-> no need to pay for upfront (for storage) and U HAVE TO pay only what u used. 
What is bucket?
	-> used to store objects, which consists of data and metadata that describe the data.
	-> Bucket can be configured and created in a specific region.
	-> when object is added to bucket , Amazon s3 generate a unique verion ID and assigns to the object.
	-> By defacult, only 100 buckets can be created in each AWS account.
	-> Within bucket have folder and subfolders within that have objects.
	-> All objects can accessed via WEB API (URL).
	-> Simple interface that helps to store and retrive any amount of data, at any point of time, from any where from the web.
	-> Scenario: how do i use in my application?
		Ex Java/PHP/.NETApplication, Applicaiton running on EC2 instancea dnthat ec2 will have its own data volume (EBS) and seperate thing called S3, thinking where do we will store and what?
		Applcation Db, data will store in ur EBS volume and application may have things like images/videos/doc those will store in S3 and then ur application use this DB for some purpose and pick up the images from S3.
Amazon S3 - Access control line:
	-> Bucket permission specifies who is allowed the access to the objects in a bucket and what perticular permission have been granted .
	-> There are built-in groups, which can be used from the Grantee box.
		-> Everyone
		-> Log Delivery: when Bucket is used to store server access logs.
		-> Me
		-> Authenticated Users
Bucket Policy:
	-> It allows users to authorize policies which either grant or deny access to any number of accounts and acroos a range or set of keys.
	-> With bucket policies, you can also define security rules that apply to more then one file, including all files or subset of files within a bucket.
	-> Example: If we have to restrict a user to access the studentdata bucket then we can apply the security with the help JSON script and after that user will not able to access the bucket.
	-> Sample JSON :
		{
			"Version": "2017-00-17",
			"Statement": [
				{
					"Effect": "Allow",
					"Principal":{
						"AWS": ["arn:aws:iam::<a/c_ID>:user/amar",
								"arn:aws:iam::<Acc_ID>:root"]
					},
					"Action": "s3:*",
					"Resource": ["arn:aws:s3:::my_bucket",
								 "arn:aws:s3:::mybucket/*"]
				}
			]
		}
Types of S3 storage classes:
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~|
Characteristics		 |		Standard	|	Standard -Infrequent 	|				 |
					 |					|		   Acess			|	Glacier		 |
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~|
Durability			 | 99.9999...(11)%	| 		  99.9999%			|	99.99...(11)%|---> Chance of data lost (it's Virtual 0)
Availability		 | 		99.99%		| 		  99.90%			|	N/A			 |
Min_Object_size		 |	   No Limit		| 		  128Kb				|	No Limit	 |
Min_Storage_Duration | No Min Duration	| 		  30Days			|	90Days		 |
First_byte_Latency	 | Milliseconds		| 		Milliseconds		|	4Hours		 |
Retrevel fee		 |		No Fee		| 	   Per GB retreved		|	Per Gb 		 |
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
	-> Durability of S3 standared is 11 nine's 
	->Standard - having lower availability
Amazon S3 - Reduced Redundance Storage (RRS):
	-> Reduced Redundancy Storage (RRS) is an Amazon S3 storage option that enables customers to store noncritical, reproducible data at lower levels of redundancy than Amazon S3â€™s standard storage. 
	-> It provides a highly available solution for distributing or sharing content that is durably stored elsewhere, or for storing thumbnails, transcoded media, or other processed data that can be easily reproduced. 
	-> The RRS option stores objects on multiple devices across multiple facilities, providing 400 times the durability of a typical disk drive, but does not replicate objects as many times as standard Amazon S3 storage.
	-> Designed to provide 99.99% durability and 99.99% availability of objects over a given year. 
	-> Designed to sustain the loss of data in a single facility.
Cross-Region Replication:
	-> Replication enables automatic, asynchronous copying of objects across Amazon S3 buckets. 
	-> Buckets that are configured for object replication can be owned by the same AWS account or by different accounts. 
	-> You can copy objects between different AWS Regions or within the same Region.
	-> Replication in two different regions with same key name and metadata.
Versioning:
	-> Versioning is a means of keeping multiple variants of an object in the same bucket. 
	-> You can use versioning to preserve, retrieve, and restore every version of every object stored in your Amazon S3 bucket.
	-> Versioning-enabled buckets enable you to recover objects from accidental deletion or overwrite.
	-> Once you version-enable a bucket, it can never return to an unversioned state. But versioning can be suspend on that bucket. By default it is on OFF state.
Amazon S3 Transfer Acceleration:	
	-> Amazon S3 Transfer Acceleration enables fast, easy, and secure transfers of files over long distances between your client and an S3 bucket. 
	-> Transfer Acceleration takes advantage of Amazon CloudFrontâ€™s globally distributed edge locations. 
	-> As the data arrives at an edge location, data is routed to Amazon S3 over an optimized network path.

###---LAB: Restoing an Amazon EBS volume from a Snapshot---###
-> EBS is not a seperate servics it is part of EC2

Step-1: To create a new (empty) EBS volume using the console:
	-> Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.
	-> From the navigation bar, select the Region in which you would like to create your volume. 
	-> In the navigation pane, choose ELASTIC BLOCK STORE, Volumes.
	-> Choose Create Volume.
	-> For Volume Type, choose a volume type. 
		-> General Purpose SSD	---> used for DataBase
		-> Provisioned IOPS SSD	---> used for DataBase
		-> Magnetic 			---> Used for Storage
		-> Throughput optimized HDD	---> used for Hadoop
		-> Cold HDD				---> used for Hadoop
	-> For Size (GiB), type the size of the volume. 
	-> With a Provisioned IOPS SSD volume, for IOPS, type the maximum number of input/output operations per second (IOPS) that the volume should support.
		-> Bigger the volume higer the performance. i.e: 3IOPS per GiB.
	-> For Availability Zone, choose the Availability Zone in which to create the volume. EBS volumes can only be attached to EC2 instances within the same Availability Zone.
	-> (Optional) If the instance type supports EBS encryption and you want to encrypt the volume, select Encrypt this volume and choose a CMK. If encryption by default is enabled in this Region, EBS encryption is enabled and the default CMK for EBS encryption is chosen. You can choose a different CMK from Master Key or paste the full ARN of any key that you can access. 
	-> (Optional) Choose Create additional tags to add tags to the volume. For each tag, provide a tag key and a tag value. For more information, see Tagging Your Amazon EC2 Resources.
	-> Choose Create Volume. After the volume status is Available, you can attach the volume to an instance.
	
Step-2: To attach an EBS volume to an instance using the console:
-> You can attach an available EBS volume to one of your instances that is in the same Availability Zone as the volume.
	1) Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.
	2) In the navigation pane, choose Elastic Block Store, Volumes.
	3) Select an available volume and choose Actions, Attach Volume.
	4) For Instance, start typing the name or ID of the instance. Select the instance from the list of options (only instances that are in the same Availability Zone as the volume are displayed).
	5) For Device, you can keep the suggested device name, or type a different supported device name. 
	6) Choose Attach.
	7) Connect to your instance and mount the volume.
Note: Volume can be attached to the server (instance) within the same Zone only.	
	-> Just attaching not enough to use the volume. You need to go into the Operating System, install the file system and need to mount the volume.
	-> Goto Instance, You can see instance details that there are now Blockdevices are root volume and attached volume (which we have attached just now).
	
	
Step-3: Detaching an Amazon EBS Volume from an Instance:
	-> You can detach an Amazon EBS volume from an instance explicitly or by terminating the instance. 
	-> However, if the instance is running, you must first unmount the volume from the instance.
	-> If an EBS volume is the root device of an instance, you must stop the instance before you can detach the volume.	
	
	1) Use the following command to unmount the /dev/sdh device.
		[ec2-user ~]$ umount -d /dev/sdh
	2) Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.
	3) In the navigation pane, choose Volumes.
	4) Select a volume and choose Actions, Detach Volume.
	5) In the confirmation dialog box, choose Yes, Detach.
	
Step-4: Creating a Snapshot:
	-> You can create a point-in-time snapshot of an EBS volume and use it as a baseline for new volumes or for data backup. 
	-> If you make periodic snapshots of a volume, the snapshots are incremental.
	
	1) Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.
	2) Choose Snapshots under Elastic Block Store in the navigation pane.
	3) Choose Create Snapshot.
	4) For Select resource type, choose Volume.
	5) For Volume, select the volume.
	6) (Optional) Enter a description for the snapshot.
	7) (Optional) Choose Add Tag to add tags to your snapshot. For each tag, provide a tag key and a tag value.
	8) Choose Create Snapshot
(OR)
	1) Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.
	2) In the navigation pane, choose Elastic Block Store, Volumes.
	3) Select an available volume and choose Actions, Create Snapshot.
	4) Provide the Name and Description of the Snapshot.
	5) Choose Create.
	
Step-5: Creating a Multi-Volume Snapshot:
	1) Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.
	2) Choose Snapshots under Elastic Block Store in the navigation pane.
	3) Choose Create Snapshot.
	4) For Select resource type, choose Instance.
	5) Select the instance ID for which you want to create simultaneous backups for all of the attached EBS volumes. Multi-volume snapshots support up to 40 EBS volumes per instance.
	6) (Optional) Set Exclude root volume.
	7) (Optional) Set Copy tags from volume flag to automatically copy tags from the source volume to the corresponding snapshots. This sets snapshot metadataâ€”such as access policies, attachment information, and cost allocationâ€”to match the source volume.
	8) (Optional) Choose Add Tag to add tags to your snapshot. For each tag, provide a tag key and a tag value.
	9) Choose Create Snapshot.
Note: During snapshot creation, the snapshots are managed together. If one of the snapshots in the volume set fails, the other snapshots are moved to error status for the volume set.

Step-6: Restoring an Amazon EBS Volume from a Snapshot:
	-> You can restore an Amazon EBS volume with data from a snapshot stored in Amazon S3. 
	-> You must know the ID of the snapshot and you must have access permissions for the snapshot.
	
	1) Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.
	2) From the navigation bar, select the region that your snapshot is located in.
		-> To restore the snapshot to a volume in a different region, you can copy your snapshot to the new region and then restore it to a volume in that region. 
	3) In the navigation pane, choose ELASTIC BLOCK STORE, Volumes.
	4) Choose Create Volume.
	5) For Volume Type, choose a volume type. 
	6) For Snapshot ID, start typing the ID or description of the snapshot from which you are restoring the volume, and choose it from the list of suggested options.
	7) (Optional) Select Encrypt this volume to change the encryption state of your volume. This is optional if encryption by default is enabled. Select a CMK from Master Key to specify a CMK other than the default CMK for EBS encryption.
	8) For Size (GiB), type the size of the volume, or verify that the default size of the snapshot is adequate.
		-> If you specify both a volume size and a snapshot, the size must be equal to or greater than the snapshot size. When you select a volume type and a snapshot, the minimum and maximum sizes for the volume are shown next to Size. 
	9) With a Provisioned IOPS SSD volume, for IOPS, type the maximum number of input/output operations per second (IOPS) that the volume should support.
	10) For Availability Zone, choose the Availability Zone in which to create the volume. EBS volumes can only be attached to EC2 instances in the same Availability Zone.
	11) (Optional) Choose Create additional tags to add tags to the volume. For each tag, provide a tag key and a tag value.
	12) Choose Create Volume.
	13) After you've restored a volume from a snapshot, you can attach it to an instance to begin using it. For more information, see Attaching an Amazon EBS Volume to an Instance.
	14) If you restored a snapshot to a larger volume than the default for that snapshot, you must extend the file system on the volume to take advantage of the extra space. For more information, see Amazon EBS Elastic Volumes.
(OR)	
	1) Open the Amazon EC2 console at https://console.aws.amazon.com/ec2/.
	2) In the navigation pane, choose Elastic Block Store, Snapshots.
	3) Select an available Snapshot to create a volume and choose Actions, Create Volume.
	4) Provide the Volume Type, Size (GiB) and AZ.
	5) Choose Create.

Note: Snapshot's stored in S3, so it will be available in any AZ in the region.	U can create a volume in different zone as well by using Snapshot.
-> It is cross region service (S3).

###---AWS CLI---###
1) Installing the AWS CLI:
	a) Prerequisites
		-> Required Python 2 version 2.7+ or Python 3 version 3.4+
	b) Installing the AWS CLI Using pip:
		-> If you have Python version 3 installed, we recommend that you use the pip3 command.
			# pip3 install awscli --upgrade --user
		-> Verify that the AWS CLI installed correctly by running
			# aws --version		----> Verify the setup DONE
   			 aws-cli/1.16.246 Python/3.7.4 Linux/4.14.133-113.105.amzn2.x86_64 botocore/1.12.236
   			 
   			# pip3 list -o
   			 Package    Version  Latest   Type 
   			 ---------- -------- -------- -----
   			 awscli     1.16.170 1.16.198 wheel
   			 botocore   1.12.160 1.12.188 wheel

2) Configuring the AWS CLI
	-> the aws configure command is the fastest way to set up your AWS CLI installation.
		$ aws configure
		AWS Access Key ID [None]: <Access_Key>
		AWS Secret Access Key [None]: <Secret_Key>
		Default region name [None]: <Region_AZ>
		Default output format [None]: json
	
	-> The CLI credentials file located at "~/.aws/credentials"
	-> The CLI configuration file located at "located at ~/.aws/config"
	-> Command line options â€“ You can specify --region, --output, and --profile as parameters on the command line.
		Ex: # aws configure --profile <profilename>		----> You can create configurations that you can refer to with a name by specifying the --profile option and assigning a name (user_name).
			# aws ec2 describe-instances --output table --region us-east-1
	-> Environment variables â€“ You can store values in the environment variables: AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, and AWS_SESSION_TOKEN. If they are present, they are used.

3) Add a named profile for the administrator user in the AWS CLI config file. You use this profile when running the AWS CLI commands.
	[profile default]
    aws_access_key_id = defacult access key ID
    aws_secret_access_key = defacult secret access key
    region = aws-region
	
	[profile adminuser]
    aws_access_key_id = adminuser access key ID
    aws_secret_access_key = adminuser secret access key
    region = aws-region
	
Scenario's:
a) Create a Snapshot:
	1) Configure AWS CLI with perticular user
	2) Goto IAM -> Users -> Create new users -> Enter name -> Create
	3) Copy the Access_Key and Secret_Access_Key and configure in AWS CLI by using "aws configure"
	4) This user have to permission to execute perticular task (Create Snapshot), So need to create a permission to this user
	5) Goto IAM -> Users -> Select user -> Attach Policy -> Choose which permission as u need (ex: AmazonEC2FullAccess) -> Attach Policy.
	6) Now run the below command to create a snapshot
	   # aws ec2 create-snapshot --volume-id vol-1234567890abcdef0 --description "This is my root volume snapshot"
	7) For Verification, Goto EC2 -> ELASTIC BLOCK STORE -> Snapshots -> here u will able to find the new snapshot what u created now.
	
###---LAB: Hosting a website on Amazon S3---###
Step-1: create an S3 bucket
	-> You are not charged for creating a bucket; you are charged only for storing objects in the bucket and for transferring objects in and out of the bucket.
	
	1) Sign in to the AWS Management Console and open the Amazon S3 console at https://console.aws.amazon.com/s3/.
	2) choose Create bucket.
	3) In the Bucket name field, type a unique DNS-compliant name for your new bucket.
		-> The name must be unique across all existing bucket names in Amazon S3.
		-> After you create the bucket, you cannot change the name, so choose wisely.
		-> Choose a bucket name that reflects the objects in the bucket because the bucket name is visible in the URL that points to the objects that you're going to put in your bucket
		-> when u creating website, the bucket name should match with the DNS name of the website. (Ex: mywebapp.domain_name.com)
	4) For Region, choose as the Region where you want the bucket to reside.
	5) Choose Create.
	
Step-2: upload an object to a bucket
	-> Now that you've created a bucket, you're ready to add an object to it. An object can be any kind of file: a text file, a photo, a video, and so on.
	
	1) In the Bucket name list, choose the name of the bucket that you want to upload your object to.
	2) If you wnat to create a folder, choose Create folder and give the folder name.
	3) Lets create simple html file to upload into S3.
		# vi s3webapphome.html
		<h1>hello from S3!</h1>
		<p>wasnt that easy?</p>
	4) Choose Upload - > choose Add files to choose the file to upload -> choose Open -> Choose Upload

Step-3: View an Object
	-> Now that you've added an object to a bucket, you can view information about your object and download the object to your local computer.
	
	1) In the Bucket name list, choose the name of the bucket that you created.
	2) In the Name list, select the check box next to the object for which you want an overview.
		(a) To download the object, choose Download in the object overview panel. To copy the path of the object to the clipboard, choose Copy Path.
			-. By using this link u can access the page (object)
		(b) If versioning is enabled on the bucket, choose Latest versions to list the versions of the object. You can then choose the download icon to download an object version, or choose the trash can icon to delete an object version.
	3) In the Name list, choose the name of the object you want to view the properties for.
		-> Choose Properties. Here you can configure the following properties for the object.
			(a) Versioning â€“ Versioning enables you to keep multiple versions of an object in one bucket. By default, versioning is disabled for a new bucket.
			(b) Server access logging â€“ Server access logging provides detailed records for the requests that are made to your bucket. By default, Amazon S3 does not collect server access logs.
			(c) Static website hosting â€“ You can host a static website on Amazon S3. To enable static website hosting, choose Static website hosting and then specify the settings you want to use.
			(d) Object-level logging â€“ Object-level logging records object-level API activity by using CloudTrail data events.
			(e) Storage class â€“ Each object in Amazon S3 has a storage class associated with it. The storage class that you choose to use depends on how frequently you access the object. The default storage class for S3 objects is STANDARD. 
			(b) Encryption â€“ You can encrypt your S3 objects.
			(c) Metadata â€“ Each object in Amazon S3 has a set of name-value pairs that represents its metadata.
			(d) Tags â€“ You can add tags to an S3 object. 

Step-4: Setting Bucket and Object Access Permissions
-> You grant access permissions to your buckets and objects by using resource-based access policies.
-> Bucket access permissions specify which users are allowed access to the objects in a bucket and which types of access they have. 
-> Object access permissions specify which users are allowed access to the object and which types of access they have. For example, one user might have only read permission, while another might have read and write permissions.
-> Bucket and object permissions are independent of each other. An object does not inherit the permissions from its bucket.
-> To grant access to your buckets and objects to other AWS accounts and to the general public, you use resource-based access policies known as access control lists (ACLs).
	
	1) In the Name list, choose the name of the object you want to view the permission for.
		-> Choose Permission, Here you can configure the following permission for the object.
			(a) Block public access - Amazon S3 block public access prevents the application of any settings that allow public access to data within S3 buckets.
			(b) Access Control List - You can grant permissions to other AWS account users or to predefined groups. The user or group that you are granting permissions to is called the grantee. By default, the owner, which is the AWS account that created the bucket, has full permissions.
			(c) Bucket Policy - You add a bucket policy to a bucket to grant other AWS accounts or IAM users access permissions for the bucket and the objects in it. Object permissions apply only to the objects that the bucket owner creates.
			(d) CORS Configuration - cross-origin resource sharing (CORS) allows client web applications that are loaded in one domain to interact with resources in another domain.
				-> A CORS configuration is an XML document that defines rules that identify the origins that you will allow to access your bucket, the operations (HTTP methods) supported for each origin, and other operation-specific information.
	2) S3 -> choose bucket -> Permission -> Bucket Policy -> By using policy gerentor generate JSON policy and use it. -> Save
	3) Policy generater:
		(a) select type of polciy: S3 bucket policy	---> It support only SQS Queue, S3 bucket, VPC Endpoint, IAM and SNS Topic's policies.
		(b) Add Statement:
			-> Effect: ()Allow	()Deny
			-> Principle: 	---> who want to access this object (* - Anybody in the world)
			-> AWS Service: Amazon S3
			-> Action: 		---> Which activity have to perform (Ex: GetObject, DeleteObject, CreateObjects, DeleteBucket & etc)
			-> Amazon Resource Name (ARN): 	---> which S3 bucket (Ex: arn:aws:s3:::mywebapp.amara.com)
			
Step-5: configure an S3 bucket for static website hosting
-> On a static website, individual webpages include static content, and they might also contain client-side scripts.
	1) Sign in to the AWS Management Console and open the Amazon S3 console at https://console.aws.amazon.com/s3/.
	2) In the Bucket name list, choose the name of the bucket that you want to enable static website hosting for.
	3) Choose Properties -> Choose Static website hosting -> Choose Use this bucket to host a website -> Choose Save.
		(a) In Index document, enter the name of the index document, which is typically index.html. (Ex: s3webapphome.html )
		(b) (Optional) For 4XX class errors, you can optionally provide your own custom error document that provides additional guidance for your users. (Ex: 404.html)	
	4) To disable block public access for the bucket, follow these steps
		(a) Select the bucket, and choose Edit public access settings.
		(b) Clear Block all public access, and choose Save.
		(c) To confirm your changes, enter confirm, and then choose Confirm.
		(d) Add a bucket policy to the website bucket that grants everyone access to the objects in the bucket.
	5) Once you turned ON, you have endpoint. By using this Endpoint u can able to access the page.
		
https://docs.aws.amazon.com/AmazonS3/latest/user-guide/static-website-hosting.html?shortFooter=true
https://docs.aws.amazon.com/AmazonS3/latest/gsg/CopyingAnObject.html	